# -*- coding: utf-8 -*-
"""Couleur de Division avec CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ks0Enm8pbef9Q02-sHO-DK4hoDDxy6am
"""

# Commented out IPython magic to ensure Python compatibility.
#Importation des librairies
import pathlib
import numpy as np
import os
import matplotlib.pyplot as plt
import random
import math
import cv2
from tensorflow.keras.preprocessing.image import ImageDataGenerator
try:
  # %tensorflow_version only exists in Colab.
#   %tensorflow_version 2.x
except Exception:
  pass
import tensorflow as tf

from tensorflow import keras
from tensorflow.keras import layers

print(tf.__version__)

#Importation du Google Drive
from google.colab import drive
drive.mount('/content/drive')

#Importation des images et formatage
#Création des catégories que le blason peut prendre, et association des blasons avec leurs catégories depuis la fonction d'isolement
import base64
from io import BytesIO
from PIL import Image

CATEGORIES = ["argent", "azure", "gules", "or", "purpure", "sable", "vert","aucun"]
IMG_SIZE=50
descriptions = []
imgs = []
class_num = []

def isole_categorie(desc) :
    desc = desc.replace(',','').replace('imperial','')
    desc = desc.split(' ')

    if("gyronny" in desc):
        a = desc.index("gyronny")
        return desc[a+1]

    if("quarterly" in desc):
        a = desc.index("quarterly")
        return desc[a+1]

    if ("per" in desc) :
        if("sinister" in desc):
            if (desc.index("per") == desc.index("sinister")-2) :
              a= desc.index("per")
              return desc[a+3]
        
       
        a = desc.index("per")
        return desc[a+2]
    else :
        return "aucun"
        
with open('drive/My Drive/blasons50_b64.txt') as f:
    for line in f:
        # on prend la description entière
        description_line = line.split(';')[0]

        # on prend l'image
        b64 = line.split(';')[1]
        img = Image.open(BytesIO(base64.b64decode(b64)))
        img_array = np.array(img)
        #resize array
        new_array=cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))
        imgs.append(new_array)


        categorie = isole_categorie(description_line)
        class_num.append(CATEGORIES.index(categorie))
        descriptions.append(categorie)
f.closed

# Resize array, keras préfere
descriptions = np.array(descriptions).reshape((-1, 1))
imgs = np.array(imgs).reshape(-1, IMG_SIZE, IMG_SIZE, 4)
class_num = np.array(class_num).reshape((-1, 1))

plt.imshow(imgs[401])
print(descriptions[401])

#Données pour l'entrainement

nombre_donnees = round(len(imgs),-1)
nombre_donnees_apprentissage = int(round(nombre_donnees*0.75,-1))

X = imgs[:nombre_donnees_apprentissage]
y = class_num[:nombre_donnees_apprentissage]

# Pour les test
X_test = imgs[nombre_donnees_apprentissage:nombre_donnees]
y_test = class_num[nombre_donnees_apprentissage:nombre_donnees]

# Print----------------------------
print (len(X))
print (len(X_test))

#Création du modèle
model1 = tf.keras.Sequential([
    tf.keras.layers.Conv2D(32, (3,3), padding='same', activation=tf.nn.relu,
                           input_shape=(IMG_SIZE, IMG_SIZE, 4)),
    tf.keras.layers.MaxPooling2D((2, 2), strides=2),
    tf.keras.layers.Conv2D(64, (3,3), padding='same', activation=tf.nn.relu),
    tf.keras.layers.MaxPooling2D((2, 2), strides=2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation=tf.nn.relu),
    tf.keras.layers.Dense(128, activation=tf.nn.relu),
    tf.keras.layers.Dense(8,  activation=tf.nn.softmax)
])

model1.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

datagen = ImageDataGenerator(
      rescale=1.3/255,
      rotation_range=10,
      zoom_range=0.2,
      brightness_range=(0.3, 1.0),
      width_shift_range=0.1,
      fill_mode='constant',
      cval=255)

#Entrainement
model1.fit_generator(
        datagen.flow(X, y, batch_size=32),
        epochs=6,
        validation_data=(X, y))

model1.save('CouleurDivisionCNNSayian.h5')

Validation et prédictions:

test_loss, test_accuracy = model1.evaluate(X_test, y_test)
print('Accuracy on test dataset:', test_accuracy)

a = random.randint(0,len(X_test))

img = X_test[a]
plt.imshow(img)
img = np.array([img],dtype="float16")
print(CATEGORIES[y_test[a][0]])

predictions = model1.predict(img)
print(CATEGORIES[np.argmax(predictions[0])])