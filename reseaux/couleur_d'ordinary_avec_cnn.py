# -*- coding: utf-8 -*-
"""Couleur d'Ordinary avec CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12DQZzaLe7GUlpZOsC6J9k7NVtbJsIB68
"""

# Commented out IPython magic to ensure Python compatibility.
#Importation des librairies
import pathlib
import numpy as np
import os
import matplotlib.pyplot as plt
import random
import math
import cv2
from tensorflow.keras.preprocessing.image import ImageDataGenerator
try:
  # %tensorflow_version only exists in Colab.
#   %tensorflow_version 2.x
except Exception:
  pass
import tensorflow as tf

from tensorflow import keras
from tensorflow.keras import layers

print(tf.__version__)

#Importation du Google Drive
from google.colab import drive
drive.mount('/content/drive')

"""# Classements des données"""

#Importation des images et formatage
#Création des catégories que le blason peut prendre, et association des blasons avec leurs catégories depuis la fonction d'isolement
import base64
from io import BytesIO
from PIL import Image

INPUT_PATH = 'drive/My Drive/blasons50_b64.txt'
COULEURS = ["argent", "azure", "gules", "or", "purpure", "sable", "vert","aucun"]
ORDINARIES = ['bend', 'chevron', 'cross', 'fess', 'pale', 'saltire']  # bend sinister est un cas a traiter a part
IMG_SIZE = 50
descriptions = []
imgs = []
class_num = []

def get_color(desc):
    # print(desc)
    desc_str = desc
    desc = desc.replace(',','')
    desc = desc.split(' ')

    if 'over a' in desc_str:
        index_nom_ordinary = desc.index('over') + 2
        if desc[index_nom_ordinary+1] == 'sinister':
            return desc[index_nom_ordinary + 2]
        else:
            return desc[index_nom_ordinary + 1]
    else:
        return 'aucun'
        
with open(INPUT_PATH) as f:
    for line in f:
        # on prend la description entière
        description_line = line.split(';')[0]

        # on prend l'image
        b64 = line.split(';')[1]
        img = Image.open(BytesIO(base64.b64decode(b64)))
        img_array = np.array(img)

        #resize array
        #new_array=cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))
        #imgs.append(new_array)

        imgs.append(img_array)

        color = get_color(description_line)
        class_num.append(COULEURS.index(color))
        descriptions.append(color)

# Resize array, keras préfere
descriptions = np.array(descriptions).reshape((-1, 1))
imgs = np.array(imgs).reshape(-1, IMG_SIZE, IMG_SIZE, 4)
class_num = np.array(class_num).reshape((-1, 1))

n=56

plt.imshow(imgs[n])
print(descriptions[n])

#Données pour l'entrainement

nombre_donnees = round(len(imgs),-1)
nombre_donnees_apprentissage = int(round(nombre_donnees*0.75,-1))

X = imgs[:nombre_donnees_apprentissage]
y = class_num[:nombre_donnees_apprentissage]

# Pour les test
X_test = imgs[nombre_donnees_apprentissage:nombre_donnees]
y_test = class_num[nombre_donnees_apprentissage:nombre_donnees]

# Print----------------------------
print (len(X))
print (len(X_test))

"""# Création du réseau"""

#Création du modèle
model1 = tf.keras.Sequential([
    tf.keras.layers.Conv2D(32, (3,3), padding='same', activation=tf.nn.relu,
                           input_shape=(IMG_SIZE, IMG_SIZE, 4)),
    tf.keras.layers.MaxPooling2D((2, 2), strides=2),
    tf.keras.layers.Conv2D(64, (3,3), padding='same', activation=tf.nn.relu),
    tf.keras.layers.MaxPooling2D((2, 2), strides=2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation=tf.nn.relu),
    tf.keras.layers.Dense(128, activation=tf.nn.relu),
    tf.keras.layers.Dense(len(COULEURS),  activation=tf.nn.softmax)
])

model1.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

"""# Entrainement"""

datagen = ImageDataGenerator(
      rescale=1.3/255,
      rotation_range=10,
      zoom_range=0.2,
      brightness_range=(0.3, 1.0),
      width_shift_range=0.1,
      fill_mode='constant',
      cval=255)

#Entrainement
model1.fit_generator(
        datagen.flow(X, y, batch_size=32),
        epochs=6,
        validation_data=(X, y))

model1.save('CouleurOrdinaryCNNSayian.h5')

"""# Validation et prédictions"""

test_loss, test_accuracy = model1.evaluate(X_test, y_test, steps=math.ceil(len(X_test)/10))
print('Accuracy on test dataset:', test_accuracy)

a = random.randint(0,len(X_test))

img = X_test[a]
plt.imshow(img)
img = np.array([img],dtype="float16")
print(COULEURS[y_test[a][0]])

predictions = model1.predict(img)
print(COULEURS[np.argmax(predictions[0])])
print(descriptions[a])